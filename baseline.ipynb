{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfqA4M7Ih9a4VecaBoZWWu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/RL/blob/main/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0c-1uPw3osgC"
      },
      "outputs": [],
      "source": [
        "# 1. å®‰è£å¿…è¦çš„åº« (ä½¿ç”¨ Gymnasium, é€™æ˜¯ OpenAI Gym çš„ç¶­è­·ç‰ˆæœ¬)\n",
        "#!pip install gymnasium stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# --- å¸¸æ•¸å®šç¾© ---\n",
        "CONVEYOR_LENGTH = 10.0  # è¼¸é€å¸¶ç¸½é•·åº¦ (ç±³)\n",
        "ARM_RANGE = 2.0         # æ©Ÿæ¢°æ‰‹è‡‚çš„å·¥ä½œç¯„åœ (X, Y è»¸)\n",
        "ARM_Z = 1.5             # æ©Ÿæ¢°æ‰‹è‡‚çš„å›ºå®šé«˜åº¦ (Z è»¸)\n",
        "V_MAX = 0.5             # è¼¸é€å¸¶æœ€å¤§é€Ÿåº¦ (ç±³/ç§’)\n",
        "TIME_STEP = 0.1         # æ¨¡æ“¬æ™‚é–“æ­¥é•· (ç§’)\n",
        "MAX_PRODUCTS = 5        # è¼¸é€å¸¶ä¸Šæœ€å¤šç”¢å“æ•¸é‡\n",
        "\n",
        "class ConveyorAssemblyEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    è¼¸é€å¸¶çµ„è£ç³»çµ±çš„å¼·åŒ–å­¸ç¿’ç’°å¢ƒ (é€£çºŒæ§åˆ¶ç°¡åŒ–ç‰ˆ)\n",
        "    Agent: æ©Ÿæ¢°æ‰‹è‡‚æ§åˆ¶å™¨ + è¼¸é€å¸¶é€Ÿåº¦æ§åˆ¶å™¨\n",
        "    \"\"\"\n",
        "    metadata = {'render_modes': ['human'], 'render_fps': 30}\n",
        "\n",
        "    def __init__(self, render_mode=None):\n",
        "        super(ConveyorAssemblyEnv, self).__init__()\n",
        "\n",
        "        # --- ç‹€æ…‹ç©ºé–“ (Observation Space) ---\n",
        "        # ç‹€æ…‹å‘é‡åŒ…å«ï¼š\n",
        "        # 1. ç”¢å“ 1 - 5 çš„ä½ç½® (x_1, x_2, ..., x_5), 0 è¡¨ç¤ºç„¡ç”¢å“\n",
        "        # 2. æ©Ÿæ¢°æ‰‹è‡‚çš„ç•¶å‰ä½ç½® (arm_x, arm_y)\n",
        "        # 3. ç³»çµ±æ™‚é˜ (current_time)\n",
        "        # 4. å·²å®Œæˆçµ„è£çš„ç”¢å“è¨ˆæ•¸ (shipped_count)\n",
        "        self.observation_space = spaces.Box(\n",
        "            # æ³¨æ„: np.inf å’Œ MAX_PRODUCTS * 10 ç”±æ–¼è¢«è½‰æ›ç‚º float32ï¼Œæœƒæœ‰ç²¾åº¦è­¦å‘Šï¼Œä½†é€šå¸¸ä¸å½±éŸ¿ RL è¨“ç·´\n",
        "            low=np.array([0.0] * MAX_PRODUCTS + [-ARM_RANGE, -ARM_RANGE, 0.0, 0], dtype=np.float32),\n",
        "            high=np.array([CONVEYOR_LENGTH] * MAX_PRODUCTS + [ARM_RANGE, ARM_RANGE, np.inf, MAX_PRODUCTS * 10], dtype=np.float32),\n",
        "            dtype=np.float32 # ç¢ºä¿ Space çš„ dtype æ˜¯ float32\n",
        "        )\n",
        "\n",
        "        # --- å‹•ä½œç©ºé–“ (Action Space) ---\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(4,), dtype=np.float32)\n",
        "\n",
        "        self.products = []\n",
        "        self.arm_pos = np.array([0.0, 0.0], dtype=np.float32) # ç¢ºä¿å…§éƒ¨ç‹€æ…‹ä¹Ÿæ˜¯ float32\n",
        "        self.current_time = 0.0\n",
        "        self.shipped_count = 0\n",
        "        self.assembly_point = CONVEYOR_LENGTH / 2\n",
        "\n",
        "    def _get_obs(self):\n",
        "        # å°‡ç”¢å“ä½ç½®å’Œæ‰‹è‡‚ä½ç½®çµ„åˆæˆç‹€æ…‹å‘é‡\n",
        "        product_positions = np.zeros(MAX_PRODUCTS)\n",
        "        for i, product in enumerate(self.products):\n",
        "            if i < MAX_PRODUCTS:\n",
        "                product_positions[i] = product['x']\n",
        "\n",
        "        observation_vector = np.concatenate([\n",
        "            product_positions,\n",
        "            self.arm_pos,\n",
        "            np.array([self.current_time, self.shipped_count])\n",
        "        ])\n",
        "\n",
        "        # é—œéµä¿®å¾©é»: å°‡è¼¸å‡ºå¼·åˆ¶è½‰æ›ç‚º np.float32\n",
        "        return observation_vector.astype(np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        self.current_time = 0.0\n",
        "        self.shipped_count = 0\n",
        "        self.arm_pos = np.array([0.0, 0.0], dtype=np.float32)\n",
        "\n",
        "        # åˆå§‹ç‹€æ…‹: æ”¾ç½® 2 å€‹ç”¢å“åœ¨è¼¸é€å¸¶èµ·é»é™„è¿‘\n",
        "        self.products = [\n",
        "            {'id': 1, 'x': 0.1, 'status': 'waiting_assembly'},\n",
        "            {'id': 2, 'x': 0.5, 'status': 'waiting_assembly'}\n",
        "        ]\n",
        "\n",
        "        # ç¢ºä¿ç”¢å“æ•¸é‡ä¸è¶…éæœ€å¤§å€¼\n",
        "        while len(self.products) < MAX_PRODUCTS:\n",
        "            # ã€é—œéµä¿®æ­£ã€‘: ä½”ä½ç¬¦ä½ç½®å¿…é ˆåœ¨ [0.0, 10.0] ç¯„åœå…§\n",
        "            self.products.append({'id': len(self.products) + 1, 'x': 0.0, 'status': 'shipped_placeholder'})\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "    def step(self, action):\n",
        "        # 1. è§£æå‹•ä½œ\n",
        "        v1_factor, v3_factor, arm_x_target_norm, arm_y_target_norm = action\n",
        "\n",
        "        # å°‡æ¨™æº–åŒ–å‹•ä½œè½‰æ›ç‚ºå¯¦éš›æ§åˆ¶é‡\n",
        "        v1 = V_MAX * np.clip(v1_factor, 0, 1)\n",
        "        v3 = V_MAX * np.clip(v3_factor, 0, 1)\n",
        "        arm_target = np.array([ARM_RANGE * arm_x_target_norm, ARM_RANGE * arm_y_target_norm], dtype=np.float32)\n",
        "\n",
        "        # 2. æ¨¡æ“¬æ©Ÿæ¢°æ‰‹è‡‚ç§»å‹•\n",
        "        arm_velocity = (arm_target - self.arm_pos) * 0.5\n",
        "        self.arm_pos += arm_velocity * TIME_STEP\n",
        "        self.arm_pos = np.clip(self.arm_pos, -ARM_RANGE, ARM_RANGE).astype(np.float32) # ä¿æŒç‚º float32\n",
        "\n",
        "        # 3. æ¨¡æ“¬è¼¸é€å¸¶å’Œç”¢å“ç§»å‹• (å…¶é¤˜é‚è¼¯ä¸è®Š)\n",
        "        for product in self.products:\n",
        "            if product['status'] == 'waiting_assembly':\n",
        "                product['x'] += v1 * TIME_STEP\n",
        "            elif product['status'] == 'waiting_shipment':\n",
        "                product['x'] += v3 * TIME_STEP\n",
        "\n",
        "        # 4. åŸ·è¡Œçµ„è£/å‡ºè²¨é‚è¼¯ (Reward Calculationçš„æ ¸å¿ƒ)\n",
        "        reward = 0.0\n",
        "\n",
        "        # ... (ä¸­ç•¥ï¼Œé‚è¼¯ä¿æŒä¸è®Š) ...\n",
        "        for product in self.products:\n",
        "            if product['status'] == 'waiting_assembly' and product['x'] > 0 and product['x'] < CONVEYOR_LENGTH:\n",
        "                arm_near_product = np.linalg.norm(self.arm_pos - [product['x'], 0]) < 0.2\n",
        "                if arm_near_product:\n",
        "                    product['status'] = 'assembled'\n",
        "                    reward += 1.0\n",
        "\n",
        "            elif product['status'] == 'assembled':\n",
        "                 arm_near_product = np.linalg.norm(self.arm_pos - [product['x'], 0]) < 0.2\n",
        "                 arm_near_shipment_start = np.linalg.norm(self.arm_pos - [CONVEYOR_LENGTH, 0]) < 0.2\n",
        "\n",
        "                 if arm_near_product:\n",
        "                     product['status'] = 'gripped'\n",
        "                 elif product['status'] == 'gripped' and arm_near_shipment_start:\n",
        "                     product['status'] = 'waiting_shipment'\n",
        "                     product['x'] = 0.1\n",
        "                     reward += 1.0\n",
        "\n",
        "            elif product['status'] == 'waiting_shipment':\n",
        "                if product['x'] >= CONVEYOR_LENGTH:\n",
        "                    product['status'] = 'shipped'\n",
        "                    self.shipped_count += 1\n",
        "                    reward += 10.0\n",
        "\n",
        "                    new_id = max(p['id'] for p in self.products) + 1\n",
        "                    self.products.append({'id': new_id, 'x': 0.1, 'status': 'waiting_assembly'})\n",
        "                    self.products = [p for p in self.products if p['status'] != 'shipped'][:MAX_PRODUCTS]\n",
        "\n",
        "\n",
        "        # 5. è¤‡åˆæ‡²ç½°é …\n",
        "        reward -= 0.1 * (v1**2 + v3**2)\n",
        "        reward -= 0.05 * TIME_STEP\n",
        "\n",
        "        if v1 > 0.4 or v3 > 0.4:\n",
        "             reward -= 0.5 * (v1 + v3)\n",
        "\n",
        "        # 6. æ›´æ–°æ™‚é–“å’Œçµ‚æ­¢æ¢ä»¶\n",
        "        self.current_time += TIME_STEP\n",
        "\n",
        "        terminated = self.current_time >= 300.0\n",
        "        truncated = False\n",
        "\n",
        "        observation = self._get_obs() # è¿”å›çš„ observation å·²ç¶“æ˜¯ float32\n",
        "\n",
        "        # ã€ğŸ’¡ é—œéµä¿®å¾©é»ã€‘: å°‡ reward è½‰æ›ç‚ºæ¨™æº– Python float\n",
        "        # ä½¿ç”¨ float() å‡½æ•¸ä¾†ç¢ºä¿é¡å‹æ­£ç¢º\n",
        "        python_float_reward = float(reward)\n",
        "\n",
        "        return observation, python_float_reward, terminated, truncated, {}\n",
        "\n",
        "# æª¢æŸ¥ç’°å¢ƒæ˜¯å¦ç¬¦åˆæ¨™æº– (åœ¨ Colab ä¸­é‹è¡Œï¼Œç¢ºèªç’°å¢ƒå®šç¾©ç„¡èª¤)\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = ConveyorAssemblyEnv()\n",
        "try:\n",
        "    check_env(env, warn=True)\n",
        "    print(\"âœ… ç’°å¢ƒæª¢æŸ¥é€šé (Env Check Passed)\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ç’°å¢ƒæª¢æŸ¥å¤±æ•—: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vF8ocH6qxI3",
        "outputId": "9b6239ed-ed6b-4682-ca2d-bf149a2bfbc6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ç’°å¢ƒæª¢æŸ¥é€šé (Env Check Passed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "# è¨­ç½® TensorBoard log è·¯å¾‘\n",
        "LOG_DIR = \"./assembly_ppo_tensorboard/\"\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "class CustomCallback(BaseCallback):\n",
        "    \"\"\"\n",
        "    è‡ªå®šç¾©å›èª¿å‡½æ•¸ï¼Œç”¨æ–¼åœ¨è¨“ç·´æœŸé–“å ±å‘Šé€²åº¦\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose=0):\n",
        "        super(CustomCallback, self).__init__(verbose)\n",
        "        self.check_freq = 5000  # æ¯ 5000 æ­¥ä¿å­˜ä¸€æ¬¡\n",
        "        self.save_path = './best_model'\n",
        "        os.makedirs(self.save_path, exist_ok=True)\n",
        "        self.best_mean_reward = -np.inf\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            # ç°¡åŒ–è©•ä¼°: ä½¿ç”¨è¨“ç·´éç¨‹ä¸­çš„å¹³å‡çå‹µä½œç‚ºæŒ‡æ¨™\n",
        "            mean_reward = np.mean(self.model.ep_info_buffer[-10:]) if self.model.ep_info_buffer else -np.inf\n",
        "\n",
        "            if mean_reward > self.best_mean_reward:\n",
        "                self.best_mean_reward = mean_reward\n",
        "                if self.verbose > 0:\n",
        "                    print(f\"Saving new best model at step {self.num_timesteps} with mean reward {self.best_mean_reward:.2f}\")\n",
        "                self.model.save(os.path.join(self.save_path, 'best_model.zip'))\n",
        "        return True\n",
        "\n",
        "# 1. åˆå§‹åŒ–ç’°å¢ƒ\n",
        "env = ConveyorAssemblyEnv()\n",
        "# å°‡ç’°å¢ƒåŒ…è£åœ¨ DummyVecEnv ä¸­ä»¥å…¼å®¹ Stable Baselines3\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n",
        "# 2. å®šç¾© PPO æ¨¡å‹\n",
        "# MlpPolicy: ä½¿ç”¨å¤šå±¤æ„ŸçŸ¥å™¨ (MLP) ä½œç‚ºç­–ç•¥ç¶²è·¯\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        "    learning_rate=3e-4,\n",
        "    gamma=0.99,            # æŠ˜æ‰£å› å­ (é‡è¦–é•·æœŸçå‹µ)\n",
        "    n_steps=2048,          # æ¯æ¬¡æ›´æ–°æ¡é›†çš„æ­¥æ•¸\n",
        "    ent_coef=0.01,         # ç†µä¿‚æ•¸ (é¼“å‹µæ¢ç´¢)\n",
        "    tensorboard_log=LOG_DIR\n",
        ")\n",
        "\n",
        "print(\"--- é–‹å§‹è¨“ç·´ PPO Agent ---\")\n",
        "\n",
        "# 3. è¨“ç·´æ¨¡å‹\n",
        "TIMESTEPS = 1000 # ç¸½è¨“ç·´æ™‚é–“æ­¥\n",
        "callback = CustomCallback(verbose=1)\n",
        "\n",
        "model.learn(\n",
        "    total_timesteps=TIMESTEPS,\n",
        "    callback=callback\n",
        ")\n",
        "\n",
        "print(\"--- è¨“ç·´å®Œæˆ ---\")\n",
        "model.save(\"final_assembly_ppo_model.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKoP2fInqN5l",
        "outputId": "cbd1e5e4-f692-47c4-cc50-c2941883a50b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "--- é–‹å§‹è¨“ç·´ PPO Agent ---\n",
            "Logging to ./assembly_ppo_tensorboard/PPO_2\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 921  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 2    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "--- è¨“ç·´å®Œæˆ ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "import numpy as np\n",
        "import os\n",
        "# å‡è¨­ V_MAX åœ¨ä¹‹å‰å·²ç¶“å®šç¾©ç‚º 0.5\n",
        "\n",
        "# è¼‰å…¥æœ€ä½³æ¨¡å‹ (æˆ–æœ€çµ‚æ¨¡å‹)\n",
        "# ç¢ºä¿ 'best_model/best_model.zip' æˆ– 'final_assembly_ppo_model.zip' å­˜åœ¨\n",
        "try:\n",
        "    # å˜—è©¦è¼‰å…¥è¨“ç·´ä¸­ä¿å­˜çš„æœ€ä½³æ¨¡å‹\n",
        "    model = PPO.load(\"./best_model/best_model.zip\", env=env)\n",
        "except Exception:\n",
        "    # å¦‚æœä¸å­˜åœ¨ï¼Œå‰‡è¼‰å…¥æœ€çµ‚æ¨¡å‹\n",
        "    print(\"Warning: Best model not found. Loading final model.\")\n",
        "    model = PPO.load(\"final_assembly_ppo_model.zip\", env=env)\n",
        "\n",
        "\n",
        "# 1. è©•ä¼°æ¨¡å‹æ€§èƒ½\n",
        "print(\"\\n--- ç­–ç•¥è©•ä¼° ---\")\n",
        "# evaluate_policy æœƒè‡ªå‹•è™•ç† DummyVecEnv çš„ step è¿”å›å€¼\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "print(f\"å¹³å‡å›åˆçå‹µ: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "\n",
        "\n",
        "# 2. ç­–ç•¥é‹è¡Œæ¼”ç¤º (å–®æ¬¡å›åˆ)\n",
        "print(\"\\n--- é‹è¡Œæœ€ä½³ç­–ç•¥ ---\")\n",
        "\n",
        "# æ­£ç¢ºè§£åŒ… DummyVecEnv çš„ reset()\n",
        "# obs æ˜¯ä¸€å€‹é•·åº¦ç‚º 1 çš„é™£åˆ—ï¼ŒåŒ…å«ç¬¬ä¸€å€‹ç’°å¢ƒçš„ç‹€æ…‹\n",
        "obs = env.reset()\n",
        "\n",
        "done = False\n",
        "total_steps = 0\n",
        "V_MAX = 0.5 # é‡æ–°å®šç¾© V_MAX ä»¥é˜²ä¸Ÿå¤±\n",
        "\n",
        "while not done:\n",
        "    # æ±ºå®šæ€§å‹•ä½œ (deterministic=True) ç”¨æ–¼éƒ¨ç½²\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "\n",
        "    # DummyVecEnv çš„ step() è¿”å›äº”å€‹é™£åˆ— (obs, reward, terminated, truncated, info)\n",
        "    obs, reward, terminated, truncated = env.step(action)\n",
        "\n",
        "    # åªè¦ä»»ä½•ä¸€å€‹ç’°å¢ƒçµæŸ (terminated æˆ– truncated)ï¼Œå°±è¨­ç‚º True\n",
        "    # terminated å’Œ truncated éƒ½æ˜¯é•·åº¦ç‚º 1 çš„å¸ƒæ—é™£åˆ—\n",
        "    done = terminated[0] or truncated[0]\n",
        "\n",
        "    total_steps += 1\n",
        "\n",
        "    # ç”±æ–¼ obs æ˜¯ä¸€å€‹é™£åˆ—ï¼Œæˆ‘å€‘éœ€è¦å–ç¬¬ä¸€å€‹å…ƒç´  [0] ä¾†ç²å–å¯¦éš›çš„ç‹€æ…‹å‘é‡\n",
        "    # current_shipped æ˜¯ç‹€æ…‹å‘é‡çš„æœ€å¾Œä¸€å€‹å…ƒç´ \n",
        "    current_shipped = obs[0][-1]\n",
        "\n",
        "    if total_steps % 50 == 0:\n",
        "        # è§€å¯Ÿé—œéµç‹€æ…‹ (obs, action, reward éƒ½æ˜¯é™£åˆ—ï¼Œå– [0] ç²å–ç¬¬ä¸€å€‹ç’°å¢ƒçš„å€¼)\n",
        "        current_time = obs[0][-2]\n",
        "\n",
        "        # action æ˜¯ä¸€å€‹é™£åˆ—ï¼ŒåŒ…å«ç¬¬ä¸€å€‹ç’°å¢ƒçš„å‹•ä½œ\n",
        "        v1_ctrl = action[0][0] * V_MAX\n",
        "        v3_ctrl = action[0][1] * V_MAX\n",
        "\n",
        "        arm_x = obs[0][-4]\n",
        "        arm_y = obs[0][-3]\n",
        "\n",
        "        print(f\"Time: {current_time:.1f}s | Shipped: {current_shipped:.0f} | R: {reward[0]:.2f}\")\n",
        "        print(f\"  V1: {v1_ctrl:.2f} m/s, V3: {v3_ctrl:.2f} m/s | Arm Pos: ({arm_x:.2f}, {arm_y:.2f})\")\n",
        "\n",
        "# æœ€çµ‚çµæœ\n",
        "final_time = obs[0][-2]\n",
        "final_shipped = obs[0][-1]\n",
        "throughput = final_shipped / (final_time / 3600.0) if final_time > 0 else 0\n",
        "\n",
        "print(f\"\\nâœ… æ¨¡æ“¬å®Œæˆï¼ ç¸½æ™‚é•·: {final_time:.1f}s\")\n",
        "print(f\"ç¸½å‡ºè²¨é‡: {final_shipped:.0f} å€‹\")\n",
        "print(f\"æ›ç®—æ¯å°æ™‚å‡ºè²¨é‡ (Throughput): {throughput:.2f} å€‹/å°æ™‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dFDRrVIqUJg",
        "outputId": "b051a32b-861e-4f2b-f60f-0f3308b88424"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Best model not found. Loading final model.\n",
            "\n",
            "--- ç­–ç•¥è©•ä¼° ---\n",
            "å¹³å‡å›åˆçå‹µ: -14.00 +/- 0.00\n",
            "\n",
            "--- é‹è¡Œæœ€ä½³ç­–ç•¥ ---\n",
            "\n",
            "âœ… æ¨¡æ“¬å®Œæˆï¼ ç¸½æ™‚é•·: 0.1s\n",
            "ç¸½å‡ºè²¨é‡: 0 å€‹\n",
            "æ›ç®—æ¯å°æ™‚å‡ºè²¨é‡ (Throughput): 0.00 å€‹/å°æ™‚\n"
          ]
        }
      ]
    }
  ]
}